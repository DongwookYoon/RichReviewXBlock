/**
 * Created by venkatesh-sivaraman on 7/7/15.
 */

/**
 The audio_coordinator module contains the data model, and it handles all interactions between the web application
 and the model. The data model consists of the following components:
 - A list of audio file URLs to blobs (indexed in order of recording)
 - A mapping of timestamps to certain audio files
    - Each timestamp represents a word or space in the audio. So, an audio file representing speech can be assembled
      by the series of words and spaces in the timestamp mapping.
 - The rasterized audio file, which is generated by `renderAudio` using the timestamps above.
 A future addition would be timing the gesture annotations with the audio.
 */

'use strict';

var SPACE_RESOURCE = 12345678,
    SPACE_CHAR_DURATION = 0.2;

// To adjust the length of each space timestamp, I could use the function accessor for `startTime` and `endTime`.

function Timestamp(id, w, time_start, time_end) {
    var _resourceID = id,
        _word = w,
        startTime = time_start,
        endTime = time_end;
    this.__defineGetter__("duration", function() {
        return this.endTime - this.startTime;
    });
    this.__defineGetter__("resourceID", function() {
        return _resourceID;
    });
    this.__defineSetter__("resourceID", function(val) {
        _resourceID = val;
    });

    this.__defineGetter__("startTime", function() {
        return startTime;
    });
    this.__defineSetter__("startTime", function(val) {
        startTime = val;
    });

    this.__defineGetter__("endTime", function() {
        return endTime;
    });
    this.__defineSetter__("endTime", function(val) {
        endTime = val;
    });

    this.__defineGetter__("word", function() {
        return _word;
    });
    this.__defineSetter__("word", function(val) {
        if (!TranscriptUtils.isWordString(val)) {
            endTime = startTime + val.length * SPACE_CHAR_DURATION;
        }
        _word = val;
    });
    //this.invisible = false;
}

Timestamp.prototype.trimToLength = function (duration) {
    if (duration < this.duration) {
        var start = (this.startTime + this.endTime) / 2.0 - duration / 2.0;
        var end = (this.startTime + this.endTime) / 2.0 + duration / 2.0;
        this.startTime = start;
        this.endTime = end;
    }
};

function TimestampGroup() {
    this.resourceID = -1;
    this.word = arguments[0];
    var _children = [];
    this.children = _children;
    for (var k = 1; k < arguments.length; k++)
        _children.push(arguments[k]);
    this.removeResourceID = function (id) {
        var i = 0;
        // Remove all occurrences of this recording
        while (i < _children.length) {
            if (_children[i].resourceID == idx) {
                _children.splice(i, 1);
            }
            else if (_children[i].children) {
                _children[i].removeResourceID(id);
            }
            else {
                i++;
            }
        }
    };

    this.__defineGetter__("startTime", function(){
        return _children[0].startTime;
    });
    this.__defineGetter__("endTime", function(){
        return _children[_children.length - 1].endTime;
    });
    this.__defineGetter__("duration", function() {
        var dur = 0.0;
        for (var i = 0; i < _children.length; i++) {
            dur += _children[i].duration;
        }
        return dur;
    });

    //this.invisible = false;
}

TimestampGroup.prototype.trimToLength = function (duration) {
    if (duration < this.duration) {
        var fraction = duration / this.duration;
        for (var i = 0; i < this.children.length; i++) {
            var childTS = this.children[i];
            childTS.trimToLength(fraction * childTS.duration);
        }
    }
};

// Thanks to http://stackoverflow.com/questions/7176908/how-to-get-index-of-object-by-its-property-in-javascript
function _findWithAttr(array, attr, value) {
    for(var i = 0; i < array.length; i += 1) {
        if(array[i][attr] === value) {
            return i;
        }
    }
    return -1;
}

// Thanks to http://stackoverflow.com/questions/4288759/asynchronous-for-cycle-in-javascript
function asyncLoop(iterations, func, callback) {
    var index = 0;
    var done = false;
    var loop = {
        next: function() {
            if (done) {
                return;
            }

            if (index < iterations) {
                index++;
                func(loop);

            } else {
                done = true;
                callback();
            }
        },

        iteration: function() {
            return index - 1;
        },

        break: function() {
            done = true;
            callback();
        }
    };
    loop.next();
    return loop;
}

var AudioCoordinator = (function () {

    var pub = {};

    var _audioFiles = [];
    // Allows the audio files to be indexed to avoid repeats
    var _runningIndex = 0;
    pub.timeStamps = [];
    pub.renderedWordIntervals = null;
    pub.renderedAudioBlob = null;

    /**
     * Resets the AudioCoordinator to prepare for a new recording editing session.
     */
    pub.init = function () {
        _audioFiles = [];
        _runningIndex = 0;
        pub.timeStamps = [];
        pub.renderedWordIntervals = null;
        pub.renderedAudioBlob = null;
    };

    /**
     * Asynchronously calculates the duration of the audio file represented by `url`.
     * @param url
     * @param cb - A callback accepting one parameter, `duration`.
     * @private
     */
    var _collectAudioDuration = function (url, cb) {
        r2.audioRecorder.parseWAV(url, function (wavInfo) {
            var duration = wavInfo.samples.length / (wavInfo.bitsPerSample / 8.0 * wavInfo.sampleRate);
            cb(duration);
        });
    };

    /**
     * Use this method to add an audio resource to the working recording (not necessarily the end). If you provide
     * a URL that is already present in the list of audio resources, an error is thrown.
     * @param url - The URL pointing to a blob of WAV data.
     * @param wordIntervals - The word timing array for that audio file.
     */
    pub.addAudioResource = function (url, wordIntervals) {
        if (!url) {
            console.error("Cannot add url", url, "to the list of audio resources.");
            return;
        }
        if (_audioFiles.indexOf(url) != -1) {
            console.error("Cannot add url", url, "to the list of audio resources because it is already there.");
            return;
        }
        for (var i = 0; i < wordIntervals.length; i++) {
            if (wordIntervals[i].resourceID != SPACE_RESOURCE)
                wordIntervals[i].resourceID = _runningIndex;
        }
        _audioFiles.push({
            resourceID: _runningIndex,
            url: url,
            wordIntervals: wordIntervals
        });
        _runningIndex++;
    };

    /**
     * Use this method to remove all occurrences of an audio resource in the working recording. Does NOT actually
     * remove the audio resource itself.
     * @param url
     */
    pub.removeAudioResource = function (url) {
        if (!url) {
            console.error("Cannot remove url", url, "from the list of audio resources.");
            return;
        }
        var idx = _findWithAttr(_audioFiles, "url", url);
        if (idx != -1) {
            var i = 0;
            // Remove all occurrences of this recording
            while (i < pub.timeStamps.length) {
                if (pub.timeStamps[i].resourceID == idx) {
                    pub.timeStamps.splice(i, 1);
                } else if (pub.timeStamps[i].children) {
                    pub.timeStamps[i].removeResourceID(idx);
                    i++;
                }
                else {
                    i++;
                }
            }
        }
    };

    /**
     * Use this method to add an audio resource to the end of the working recording. You could use time_start and
     * time_end to trim off the beginning and end of the recording. If the recording URL you provide is already in
     * the list of audio resources, this method will add the interval of audio specified by time_start and time_end
     * to the end of the working recording.
     * @param url - The URL pointing to a blob of WAV data.
     * @param wordIntervals - (optional) An array of word time intervals for the audio data.
     * @param cb - (optional) A callback method (if time_end is not provided, this function will determine it
     * asynchronously).
     * @param time_start - (optional) The time, in seconds, relative to the recording at `url` at which it should
     * begin playing. Defaults to -1 (beginning of recording).
     * @param time_end - (optional) The time, in seconds, relative to the recording at `url` at which it should stop
     * playing. Defaults to -1 (end of recording).
     */
    pub.appendAudioResource = function (url, wordIntervals, cb, time_start, time_end) {
        if (!url) {
            console.error("Cannot add url", url, "to the list of audio resources.");
            return;
        }
        var idx = _findWithAttr(_audioFiles, "url", url);
        if (idx == -1) {
            pub.addAudioResource(url, wordIntervals);
            idx = _audioFiles.length - 1;
        }
        if (time_start < 0 || time_start == undefined) {
            time_start = 0;
        }
        if (time_end <= 0 || time_end == undefined) {
            console.log("Collecting audio duration asynchronously");
            _collectAudioDuration(url, function (dur) {
                time_end = dur;
                for (var i = 0; i < _audioFiles[idx].wordIntervals.length; i++) {
                    var ts = _audioFiles[idx].wordIntervals[i];
                    if (ts.startTime >= time_start || ts.endTime <= time_end ||
                        (ts.startTime <= time_start && ts.endTime >= time_end))
                        pub.timeStamps.push(ts);
                }
                if (cb) cb();
            });
        }
        else {
            for (var i = 0; i < _audioFiles[idx].wordIntervals.length; i++) {
                var ts = _audioFiles[idx].wordIntervals[i];
                if (ts.startTime >= time_start || ts.endTime <= time_end ||
                    (ts.startTime <= time_start && ts.endTime >= time_end))
                    pub.timeStamps.push(ts);
            }
        }
    };

    /**
     * Use this method to insert an audio snippet at `position` in the working recording (by Timestamp objects).
     * @param url - The URL pointing to a blob of WAV data.
     * @param position - The index of the timestamp array in which you want to insert the audio snippet.
     * @param wordIntervals - An array of word intervals for the audio.
     * @param cb - (optional) A callback method (if time_end is not provided, this function will determine it
     * asynchronously, then call cb).
     * @param time_start See appendAudioResource.
     * @param time_end See appendAudioResource.
     */
    pub.insertAudioResource = function (url, position, wordIntervals, cb, time_start, time_end) {
        if (!url) {
            console.error("Cannot add url", url, "to the list of audio resources.");
            return;
        }
        var idx = _findWithAttr(_audioFiles, "url", url);
        if (idx == -1) {
            pub.addAudioResource(url, wordIntervals);
            idx = _audioFiles.length - 1;
        }
        if (time_start < 0 || time_start == undefined) {
            time_start = 0;
        }
        if (time_end <= 0 || time_end == undefined) {
            console.log("Collecting audio duration asynchronously");
            _collectAudioDuration(url, function (dur) {
                time_end = dur;
                for (var i = 0; i < _audioFiles[idx].wordIntervals.length; i++) {
                    var ts = _audioFiles[idx].wordIntervals[i];
                    if (ts.startTime >= time_start || ts.endTime <= time_end ||
                        (ts.startTime <= time_start && ts.endTime >= time_end)) {
                        pub.timeStamps.splice(position, 0, ts);
                        position++;
                    }
                }
                if (cb) cb();
            });
        }
        else {
            for (var i = 0; i < _audioFiles[idx].wordIntervals.length; i++) {
                var ts = _audioFiles[idx].wordIntervals[i];
                if (ts.startTime >= time_start || ts.endTime <= time_end ||
                    (ts.startTime <= time_start && ts.endTime >= time_end)) {
                    pub.timeStamps.splice(position, 0, ts);
                    position++;
                }
            }
        }
    };

    // Timestamp-editing functions
    // Be sure to provide the start and end times for every timestamp you enter. Otherwise, the audio will not render.

    pub.addTimestamp = function (id, word, start, end) {
        pub.timeStamps.push(new Timestamp(id, word, start, end));
    };

    /**
     * Use this method to insert a timestamp at a particular index among the timestamps. See `spliceTimestamp` to
     * insert a timestamp at a particular clock time.
     */
    pub.insertTimestamp = function (id, position, word, start, end) {
        pub.timeStamps.splice(position, 0, new Timestamp(id, word, start, end));
    };

    pub.removeTimestamp = function (timestamp) {
        var idx = pub.timeStamps.indexOf(timestamp);
        if (idx != -1) {
            pub.timeStamps.splice(idx, 1);
        }
    };

    /**
     * Helper function for getting the metadata about the overall audio file.
     * @returns {{sampleRate: number, overlapFrames: number, totalTime: number, totalSamples: number}}
     * @private
     */
    function audioInfo_ () {
        // We assume a standard sample rate of 22,050 Hz.
        var sampleRate = 22050;
        // The overlap frames account for interpolation between two audio samples. It should only be counted once for
        // each sample (not double-counted).
        var overlapFrames = 0; //Math.floor(0.5 * sampleRate / 4) * 4;

        // Calculate the number of samples in the total audio file, and allocate an ArrayBuffer accordingly.
        var totalTime = 0.0;
        var numCounted = 0;
        for (var i = 0; i < pub.timeStamps.length; i++) {
            if (pub.timeStamps[i].startTime < 0 || pub.timeStamps[i].endTime < 0) {
                console.error("Invalid time stamp:", pub.timeStamps[i]);
                return {
                    sampleRate: sampleRate,
                    overlapFrames: overlapFrames,
                    totalTime: 0,
                    totalSamples: 0
                }
            }
            totalTime += pub.timeStamps[i].duration - overlapFrames / sampleRate;
        }
        totalTime += overlapFrames / sampleRate;

        var totalSamples = totalTime * sampleRate;
        return {
            sampleRate: sampleRate,
            overlapFrames: overlapFrames,
            totalTime: totalTime,
            totalSamples: totalSamples
        };
    }

    /**
     * This function merges any timestamps in the array that are consecutive and represent spaces. They will now be
     * represented as a single TimestampGroup object, and the individual segments can be accessed through `children`.
     * @returns {Number} - The number of timestamps that are now merged into other timestamps.
     */
    pub.mergeSpaceGroups = function () {
        var i = 0,
            firstSpaceIdx = -1,
            origLength = pub.timeStamps.length,
            slice,
            groupTS;
        while (i < pub.timeStamps.length) {
            if (!TranscriptUtils.isWordString(pub.timeStamps[i].word)) {
                if (firstSpaceIdx < 0) {
                    firstSpaceIdx = i;
                }
            } else {
                if (firstSpaceIdx > 0 && i - firstSpaceIdx > 1) {
                    slice = pub.timeStamps.slice(firstSpaceIdx, i);
                    groupTS = new (Function.prototype.bind.apply(
                        TimestampGroup,
                        [null, slice.map(function(item) { return item.word; }).join('')].concat(slice)));
                    console.log("replacing timestamps", firstSpaceIdx, "through", i, "with", groupTS);
                    pub.timeStamps.splice(firstSpaceIdx, i - firstSpaceIdx, groupTS);
                    i = firstSpaceIdx;
                }
                firstSpaceIdx = -1;
            }
            i++;
        }
        if (firstSpaceIdx > 0 && i - firstSpaceIdx > 1) {
            slice = pub.timeStamps.slice(firstSpaceIdx, i);
            groupTS = new (Function.prototype.bind.apply(
                TimestampGroup,
                [null, slice.map(function(item) { return item.word; }).join('')].concat(slice)));
            console.log("replacing timestamps", firstSpaceIdx, "through", i, "with", groupTS);
            pub.timeStamps.splice(firstSpaceIdx, i - firstSpaceIdx, groupTS);
            i = firstSpaceIdx;
        }

        return origLength - pub.timeStamps.length;
    };

    /**
     * This function trims all spaces longer than +1 SD of the mean silence duration to the mean + 1 SD.
     */
    pub.trimSpaceIntervals = function () {
        // Calculate the mean and SD of silence durations.
        var totalDur = 0.0, totalCount = 0, totalSquareDur = 0, ts;
        var spaces = [];
        for (var i = 0; i < pub.timeStamps.length; i++) {
            ts = pub.timeStamps[i];
            if (!TranscriptUtils.isWordString(ts.word)) {
                totalDur += ts.duration;
                totalCount++;
                spaces.push(ts);
            }
        }
        var mean = totalDur / totalCount;
        for (i = 0; i < spaces.length; i++) {
            totalSquareDur += Math.pow(spaces[i].duration - mean, 2);
        }
        var sd = Math.sqrt(totalSquareDur / totalCount);

        // Standardize all gaps longer than mean + sd.
        for (i = 0; i < spaces.length; i++) {
            if (spaces[i].duration > mean + sd) {
                console.log("Trimming", spaces[i], "to length", mean + sd);
                spaces[i].trimToLength(mean + sd);
            }
        }
    };

    /**
     * This function produces the final audio tokens, but not the waveform itself. This can be helpful for improving
     * performance when the audio file is not needed right away.
     */
    pub.renderWordIntervals = function () {
        var audioInfo = audioInfo_();
        if (audioInfo.totalTime == 0) {
            pub.renderedWordIntervals = [];
            return pub.renderedWordIntervals;
        }
        var wordIntervals = [];
        var runningTime = 0;

        for (var n = 0; n < pub.timeStamps.length; n++) {
            var resID = pub.timeStamps[n].resourceID;
            if (resID < 0)
                resID = SPACE_RESOURCE;
            wordIntervals.push(new Timestamp(resID,
                pub.timeStamps[n].word,
                runningTime,
                pub.timeStamps[n].duration + runningTime));
            runningTime += pub.timeStamps[n].duration;
        }
        //TODO: Overlap if it exists
        pub.renderedWordIntervals = wordIntervals;
        return wordIntervals;
    };

    /**
     * This function renders the audio from audio resources into a final WAV blob which can be played back.
     * @param cb - The callback function when the rendering is complete. It will be passed an audio blob object as
     * well as a list of word intervals.
     */
    pub.renderAudio = function (cb) {
        var audioInfo = audioInfo_();
        if (audioInfo.totalTime == 0) {
            pub.renderedWordIntervals = [];
            pub.renderedAudioBlob = null;
            if (cb)
                cb(pub.renderedAudioBlob, pub.renderedWordIntervals);
            return;
        }

        var WORKER_PATH = 'audioworker.js';
        var worker = new Worker(WORKER_PATH);
        worker.postMessage({
            command: 'init',
            config: {
                sampleRate: audioInfo.sampleRate
            }
        });

        var wordIntervals = [];
        var runningTime = 0;
        worker.onmessage = function(e){
            var blob = e.data;
            if (blob != undefined) {
                //Handle the blob
                var url = (window.URL || window.webkitURL).createObjectURL(blob);
                wordIntervals = pub.renderWordIntervals();
                pub.renderedWordIntervals = wordIntervals;
                pub.renderedAudioBlob = blob;
                if (cb)
                    cb(blob, wordIntervals);
            }
        };

        // Split up the time stamps into groups based on what resource IDs they have
        var tsGroups = [];
        var currentResID = -1;
        function addToTSGroups (array) {
            for (var n = 0; n < array.length; n++) {
                var ts = array[n];
                if (ts.children) {
                    addToTSGroups(ts.children);
                }
                else if (ts.resourceID == currentResID) {
                    tsGroups[tsGroups.length - 1].push(ts);
                } else {
                    tsGroups.push([ts]);
                    currentResID = ts.resourceID;
                }
            }
        }
        addToTSGroups(pub.timeStamps);

        asyncLoop(tsGroups.length, function (loop) {
            // Load the WAV file from memory
            var i = loop.iteration();
            var idx = _findWithAttr(_audioFiles, "resourceID", tsGroups[i][0].resourceID);
            if (tsGroups[i][0].resourceID === SPACE_RESOURCE) {
                var totSubSamples = 0;
                for (var n = 0; n < tsGroups[i].length; n++) {
                    totSubSamples += Math.floor(tsGroups[i][n].duration * audioInfo.sampleRate) * 2;
                }
                var samples = new Int8Array(totSubSamples);
                var offset = 0;
                for (n = 0; n < tsGroups[i].length; n++) {
                    var sampCount = Math.floor(tsGroups[i][n].duration * audioInfo.sampleRate) * 2;
                    var zeroArray = new Int8Array(sampCount);
                    for (var m = 0; m < sampCount; m++)
                        zeroArray[m] = 0;
                    samples.set(zeroArray, offset);

                    offset += zeroArray.length;
                    runningTime += tsGroups[i][n].duration;
                }
                worker.postMessage({
                    command: 'record',
                    buffer: [samples],
                    overlap: 0
                });
                loop.next();
                return;
            }
            r2.audioRecorder.parseWAV(_audioFiles[idx].url, function (wavInfo) {
                var totSubSamples = 0;
                for (var n = 0; n < tsGroups[i].length; n++) {
                    totSubSamples += Math.floor(tsGroups[i][n].endTime * audioInfo.sampleRate) * 2 -
                        Math.floor(tsGroups[i][n].startTime * audioInfo.sampleRate) * 2;
                }
                totSubSamples += audioInfo.overlapFrames / 2;

                var samples = new Int8Array(totSubSamples),
                    offset = 0;
                for (n = 0; n < tsGroups[i].length; n++) {
                    var maxSample = Number.POSITIVE_INFINITY,
                        startSample, endSample, subSamples;
                    if (!TranscriptUtils.isWordString(tsGroups[i][n].word)) {
                        // Find this timestamp in the original audio resource, and look for the next word timestamp.
                        var lookingForWord = false;
                        for (var m = 0; m < _audioFiles[idx].wordIntervals.length; m++) {
                            if (lookingForWord) {
                                if (TranscriptUtils.isWordString(_audioFiles[idx].wordIntervals[m].word))
                                    break;
                            } else if (_audioFiles[idx].wordIntervals[m].startTime >= tsGroups[i][n].startTime - 0.001) {
                                lookingForWord = true;
                            }
                        }
                        if (m < _audioFiles[idx].wordIntervals.length)
                            maxSample = Math.floor(_audioFiles[idx].wordIntervals[m].startTime * audioInfo.sampleRate) * 2;
                        else if (m == _audioFiles[idx].wordIntervals.length)
                            maxSample = Math.floor(_audioFiles[idx].wordIntervals[m - 1].endTime * audioInfo.sampleRate) * 2;
                    }
                    startSample = Math.floor(tsGroups[i][n].startTime * audioInfo.sampleRate) * 2;
                    endSample = Math.floor(tsGroups[i][n].endTime * audioInfo.sampleRate) * 2;
                    if (endSample > maxSample) {
                        subSamples = new Int8Array(endSample - startSample);
                        subSamples.set(wavInfo.samples.subarray(startSample, maxSample));
                        for (var p = maxSample; p < endSample; p++)
                            subSamples[p] = 0;
                    } else {
                        subSamples = wavInfo.samples.subarray(startSample, endSample);
                    }
                    samples.set(subSamples, offset);
                    offset += subSamples.length;
                    runningTime += tsGroups[i][n].duration;
                }

                worker.postMessage({
                    command: 'record',
                    buffer: [samples],
                    overlap: audioInfo.overlapFrames
                });
                loop.next();
            });
        }, function () {
            console.log("Total time:", runningTime);
            if (runningTime <= 0.001) {
                cb(null, []);
                return;
            }
            worker.postMessage({
                command: 'exportWAV',
                type: 'audio/wav'
            });
        });
    };

    return pub;
}());